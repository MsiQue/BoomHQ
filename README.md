# BoomHQ: Learning to Boost Multiple Hybrid Queries on Vector DBMSs

This repository contains the official code for the paper **BoomHQ: Learning to Boost Multiple Hybrid Queries on Vector DBMSs**.  
It includes scripts for **benchmark generation**, **hybrid query construction**, and **learning-based query optimization** on multiple vector database systems.

---

## ğŸ§© Benchmark Generation

To evaluate hybrid queries that involve **multiple vector columns** and **scalar constraints**, we design a benchmark based on both **vector-only** and **text-to-vector** datasets.  
The following table summarizes all datasets used in our experiments:

| Dataset   | Type | #Samples  | Dim  | Link                                                         |
| --------- | ---- | --------- | ---- | ------------------------------------------------------------ |
| Fungis    | v+s  | 295,938   | 768  | [ğŸ”— Fungis](https://hybridqueriesbenchmark.github.io/index.html) |
| Sift      | vâ†’s  | 1,000,000 | 128  | [ğŸ”— SIFT1M](http://corpus-texmex.irisa.fr/)                   |
| Glove     | vâ†’s  | 1,183,514 | 100  | [ğŸ”— GloVe](https://nlp.stanford.edu/projects/glove/)          |
| Deep1B    | vâ†’s  | 9,990,000 | 96   | [ğŸ”— Deep1B](https://github.com/erikbern/ann-benchmarks/tree/main) |
| Aka_title | sâ†’v  | 361,472   | 768  | [ğŸ”— IMDb Aka-Title](https://datasets.imdbws.com/)             |
| Title     | sâ†’v  | 2,528,312 | 768  | [ğŸ”— IMDb Title](https://datasets.imdbws.com/)                 |
| Aka_name  | sâ†’v  | 901,343   | 768  | [ğŸ”— IMDb Aka-Name](https://datasets.imdbws.com/)              |
| Part      | sâ†’v  | 200,000   | 768  | [ğŸ”— TPC-H Part](https://www.tpc.org/tpch/)                    |
| Partsupp  | sâ†’v  | 800,000   | 768  | [ğŸ”— TPC-H Partsupp](https://www.tpc.org/tpch/)                |
| Orders    | sâ†’v  | 1,500,000 | 768  | [ğŸ”— TPC-H Orders](https://www.tpc.org/tpch/)                  |
| Lineitem  | sâ†’v  | 6,000,000 | 768  | [ğŸ”— TPC-H Lineitem](https://www.tpc.org/tpch/)                |

---

## ğŸ§® Column Expansion for Hybrid Queries

Since our target task involves **weighted nearest-neighbor queries** across multiple vector columns combined with **scalar filtering conditions**,  
we designed a **column expansion mechanism** to generate realistic hybrid data schemas from the above datasets.

- **Scalar Column Expansion** â€” implemented in [`gen_scalar_column.py`](./gen_scalar_column.py)  
  This script adds synthetic or derived scalar attributes (e.g., price, rating, category) to simulate hybrid query conditions.

- **Vector Column Expansion** â€” implemented in [`gen_vector_column.py`](./gen_vector_column.py)  
  This script creates additional semantic vector columns by applying embedding models (e.g., BERT) to text fields, enabling multi-vector similarity queries.

Together, these scripts construct the foundation of our **BoomHQ benchmark**, enabling reproducible experiments for **Multiple Hybrid Queries (MHQ)**.

---

## ğŸ” Query Generation

After the column expansion, we automatically construct a set of benchmark queries to evaluate the systemâ€™s ability to process **Multiple Hybrid Queries (MHQ)** â€” queries that combine vector similarity and scalar filtering.

The queries are generated by two scripts:

### 1ï¸âƒ£ Single-Vector Hybrid Queries (`gen_single_col_query.py`)
This script creates **hybrid queries over a single vector column** combined with one or more scalar predicates.  
Each query randomly selects:

- A target vector column and query embedding (sampled from the same distribution).  
- A scalar condition (e.g., `price < 0.5`, `rating > 4.0`, or `category = 'A'`).  
- A similarity function (`L2`, `cosine`, or `dot`) and a top-`k` threshold.

The resulting workload allows the evaluation of how well different vector DBMSs handle combined vectorâ€“scalar predicates under varying selectivities.

---

### 2ï¸âƒ£ Multi-Vector Hybrid Queries (`gen_mul_col_query.py`)
To simulate complex real-world search scenarios, we introduce **weighted multi-vector hybrid queries**.  
These queries involve **multiple vector columns**, each contributing to the overall similarity score:


$$
\text{score}(x, q) = \sum_i w_i \cdot \text{sim}(x_i, q_i)
$$


The script supports:

- Random or rule-based weight assignment.  
- Mixed scalar conditions (range or categorical filters).  
- Query generation for various benchmark scales.  

This enables comprehensive evaluation of **multi-aspect semantic search**, where both vector relationships and scalar attributes jointly determine query results.

---

## ğŸš€ Using BoomHQ

BoomHQ provides a **learning-based framework** for optimizing hybrid queries on vector DBMSs.  
It automatically recommends **execution strategies** and **search parameters** based on data distribution and query characteristics.

### ğŸ”¹ Installation
```bash
git clone https://github.com/MsiQue/BoomHQ.git
cd BoomHQ
pip install -r requirements.txt

```

### ğŸ”¹ A Note Regarding Detailed Execution Procedures

Thank you very much for your interest in our work. As the academic paper associated with this repository is currently **under active peer review**, we are temporarily withholding the detailed, step-by-step operational guides and reproduction scripts to ensure the integrity and fairness of the review process.

We understand this may cause an inconvenience for those who wish to run and validate our method, and we sincerely apologize for this. We kindly ask for your understanding.

For readers familiar with the domain (and especially for our valued reviewers) who wish to run the code, we highly recommend **referring to the "Methodology" and "Experiment" sections of our manuscript**. The paper provides the necessary details, key information, and core logic required to configure and execute the method based on its content.

We are fully committed to open science and reproducibility. We pledge that **as soon as the paper is formally accepted and published**, we will immediately update this repository with all comprehensive running procedures, configuration details, example scripts, and supporting files.

Thank you for your patience and support.
